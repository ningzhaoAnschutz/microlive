{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating folding efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import sys\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import bigfish.stack as stack\n",
    "from PIL import Image\n",
    "import importlib\n",
    "import socket\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# Defining directories\n",
    "def find_src_directory(current_directory: Path) -> Path:\n",
    "    # Loop through the parent directories\n",
    "    for parent in current_directory.parents:\n",
    "        potential_src = parent / 'src'\n",
    "        if potential_src.is_dir():\n",
    "            return potential_src\n",
    "    return None\n",
    "\n",
    "# computer name \n",
    "computer_name = socket.gethostname()\n",
    "computer_user_name = computer_name.split('.')[0]\n",
    "\n",
    "# Defining directories\n",
    "current_dir = pathlib.Path().absolute()\n",
    "Advanced_Microscopy_dir = find_src_directory(current_dir)\n",
    "sys.path.append(str(Advanced_Microscopy_dir))\n",
    "import Advanced_Microscopy as AM \n",
    "importlib.reload(AM)\n",
    "\n",
    "import ML_SpotDetection as ML\n",
    "importlib.reload(ML)\n",
    "model = ML.ParticleDetectionCNN()\n",
    "model_path = 'particle_detection_cnn.pth'\n",
    "ML.load_model(model, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# importlib.reload(ML)\n",
    "\n",
    "# def profile_training():\n",
    "#     # your training function or call here\n",
    "#     ML.run_network(image_dir='training_crops', num_epochs=300, learning_rate=0.0000005, batch_size=256)\n",
    "\n",
    "# cProfile.run('profile_training()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_my_folder = pathlib.Path(r\"/Users/nzlab-la/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/General - Zhao (NZ) Lab/Microscope/Luis Aguilera/Live cell imaging_Folding & Nascent chains\")\n",
    "\n",
    "# data from 20240801\n",
    "#data_folder_path =path_my_folder.joinpath(r\"20240801 pNZ212 and pRS001_JF646_NoDelay_ch0 folding_ch1 nascent chains.lif\") \n",
    "#data_folder_path =path_my_folder.joinpath(r\"20240801 pNZ222 and pRS001_JF646_NoDelay_ch0 folding_ch1 nascent chains.lif\")\n",
    "\n",
    "# data from 20240801 \n",
    "data_folder_path =path_my_folder.joinpath(r\"20240806 pNZ212 and pRS001_JF646_NoDelay_ch0 folding_ch1 nascent chains.lif\")\n",
    "#data_folder_path =path_my_folder.joinpath(r\"20240806 pNZ222 and pRS001_JF646_NoDelay_ch0 folding_ch1 nascent chains.lif\")\n",
    "\n",
    "# data from 20240820\n",
    "#path_data_folder = pathlib.Path(r\"/Users/\"+computer_user_name+r\"/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/General - Zhao (NZ) Lab/Microscope/Rhiannon/Live Cell Co-translational Folding sfGFP vs wtGFP_RMS/20240820 pNZ212 or 222 and pRS001_JF646_NoDelay_50frames_ch0 folding_ch1 nascent chains\")\n",
    "#data_folder_path = path_data_folder.joinpath(r\"20240820 pNZ212_pRS001_JF646_NoDelay_50frames.lif\")  # sfGFP\n",
    "#data_folder_path = path_data_folder.joinpath(r\"20240820 pNZ222_pRS001_JF646NoDelay_50frames.lif\") # wtGFP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# importlib.reload(ML)\n",
    "\n",
    "# def profile_training():\n",
    "#     # your training function or call here\n",
    "#     ML.run_network(image_dir='training_crops', num_epochs=1000, learning_rate=0.0000005, batch_size=256)\n",
    "\n",
    "# cProfile.run('profile_training()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images, list_names, pixel_xy_um, voxel_z_um, channel_names, number_color_channels,list_time_intervals, bit_depth = AM.ReadLif(data_folder_path,show_metadata=False,save_tif=False,save_png=True,format='TZYXC').read()\n",
    "number_images = len(list_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting image\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 7, 512, 512, 2)\n"
     ]
    }
   ],
   "source": [
    "selected_image = 4\n",
    "tested_image =list_images[selected_image]\n",
    "print (tested_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_name = 'results_'+data_folder_path.stem + '_cell_id_'+str(selected_image)\n",
    "results_folder = current_dir.parents[0].joinpath('live_cell').joinpath('results_folding',results_name)\n",
    "results_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# read the tif files containing the masks as numpy arrays\n",
    "mask_file_name = 'mask_'+data_folder_path.stem+'_image_'+str(selected_image)+'.tif'\n",
    "masks = imread(str(results_folder.joinpath(mask_file_name))).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizer = AM.SliderPlotting(image_TZYXC=tested_image, masks=masks,cmap='gist_yarg',sigma=0.2)\n",
    "#visualizer.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle tracking\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "channels_cytosol = [0]\n",
    "channels_nucleus = [None] \n",
    "channels_spots = [1]\n",
    "diameter_nucleus = None \n",
    "pixel_xy_nm = int(pixel_xy_um*1000)\n",
    "voxel_z_nm = int(voxel_z_um*1000)\n",
    "list_voxels =   [voxel_z_nm , pixel_xy_nm]  # , [voxel_z_nm , pixel_xy_nm] ]\n",
    "list_psfs =  [voxel_z_nm ,pixel_xy_nm]  #, [voxel_z_nm , pixel_xy_nm] ]\n",
    "min_length_trajectory  = 2\n",
    "memory = 0\n",
    "yx_spot_size_in_px = 3\n",
    "channel_for_tracking = 1\n",
    "maximum_spots_cluster = 3\n",
    "# calculate the threshold from the histogram\n",
    "starting_threshold = AM.Utilities().calculate_threshold_from_percentage(tested_image=tested_image, masks=masks, target_percentage=20)\n",
    "starting_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(AM)\n",
    "threshold = AM.Utilities().calculate_threshold_for_spot_detection(tested_image,list_psfs,list_voxels,channels_spots, max_spots_for_threshold = 3000, show_plot=False)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(AM)\n",
    "tracker = AM.SingleTimePointSpotDetection(image_TZYXC=tested_image, \n",
    "                                        masks=masks,list_voxels=list_voxels, \n",
    "                                        list_psfs=list_psfs,\n",
    "                                        channels_spots=channels_spots, \n",
    "                                        channels_cytosol=channels_cytosol, \n",
    "                                        channels_nucleus=channels_nucleus,\n",
    "                                        yx_spot_size_in_px=yx_spot_size_in_px,starting_threshold= threshold,channel_for_tracking=channel_for_tracking)    # ,channel_for_tracking=channel_for_tracking\n",
    "tracker.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_threshold = tracker.get_threshold_and_time()[0]\n",
    "df_tracking = tracker.get_cached_dataframes()\n",
    "starting_threshold\n",
    "detected_spots = len(tracker.get_cached_dataframes() )\n",
    "\n",
    "print('Number of detected spots:', detected_spots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMAL_SNR = 0.5\n",
    "\n",
    "list_dataframes_trajectories, _ = AM.ParticleTracking (image=tested_image,channels_spots=channels_spots, masks=masks, list_voxels=list_voxels,list_psfs=list_psfs, channels_cytosol=0,channels_nucleus=None,min_length_trajectory=min_length_trajectory,threshold_for_spot_detection=starting_threshold,yx_spot_size_in_px=yx_spot_size_in_px,maximum_spots_cluster=maximum_spots_cluster).run()\n",
    "df_tracking= list_dataframes_trajectories[0]\n",
    "threshold_tracking = starting_threshold\n",
    "filtered_image = AM.Utilities().gaussian_laplace_filter_image(tested_image,list_psfs,list_voxels)\n",
    "\n",
    "# remove low quality tracks. those that have a SNR of less than 0.1\n",
    "array_selected_field_ch1= AM.Utilities().df_trajectories_to_array(dataframe=df_tracking, selected_field='snr_ch_1', fill_value='nans')\n",
    "mean_snr_ch1 = np.nanmean(array_selected_field_ch1, axis=1)\n",
    "std_snr_ch1 = np.nanstd(array_selected_field_ch1, axis=1)\n",
    "\n",
    "indices_low_quality_tracks = np.where(mean_snr_ch1 <  MINIMAL_SNR)[0]\n",
    "\n",
    "df_tracking = df_tracking[~df_tracking['particle'].isin(indices_low_quality_tracks)]\n",
    "df_tracking = df_tracking.reset_index(drop=True)\n",
    "df_tracking['particle'] = df_tracking.groupby('particle').ngroup()\n",
    "\n",
    "print('Number of tracks before filtering:', len(array_selected_field_ch1))\n",
    "print('Number of tracks after filtering:', len(df_tracking['particle'].unique()))\n",
    "\n",
    "# plot image intensity histogram\n",
    "plot_name_histogram = results_folder.joinpath('pixel_histogram_in_cell.png')\n",
    "masked_data = tested_image * masks[np.newaxis, np.newaxis, :, :, np.newaxis].astype(float)\n",
    "list_median_intensity = AM.Plots().plot_image_pixel_intensity_distribution(image=np.mean(masked_data[:,:,:,:,:],axis=0),figsize=(8, 2),bins=100,remove_outliers=True,remove_zeros=True,save_plots=True, plot_name=plot_name_histogram ,single_color =None,list_colors=channel_names,tracking_channel = channel_for_tracking,threshold_tracking=threshold_tracking)\n",
    "\n",
    "suptitle = 'Image: ' + data_folder_path.stem[:16]+'- '+list_names[selected_image] +' - Cell_ID: '+ str(selected_image)\n",
    "\n",
    "plot_name_original_image = results_folder.joinpath('original_image.png')\n",
    "AM.Plots().plot_images(image_ZYXC=tested_image[0], df=df_tracking, masks=masks, show_trajectories=True, suptitle=suptitle,figsize=(12, 3), show_plots=True,selected_time=0, use_maximum_projection=True, use_gaussian_filter=True,cmap='binary',min_max_percentile=[0.5,99.2],show_gird=False,save_plots=True,plot_name=plot_name_original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection a time point in the image and dataframe for the plot.\n",
    "save_image_for_publication = False\n",
    "if save_image_for_publication:\n",
    "    time_point = 15\n",
    "    df_time = df_tracking[df_tracking['frame'] == time_point]\n",
    "    image_to_plot = tested_image[time_point,... ]\n",
    "    plot_name_detection = results_folder.joinpath('detected_spots.png')\n",
    "    AM.Plots().plot_selected_cell_colors( image=image_to_plot, df=df_time, spot_type=1, min_ts_size=None, show_spots=True,use_gaussian_filter = True, image_name=plot_name_detection,microns_per_pixel=pixel_xy_um,\n",
    "                                        show_legend=False,list_channel_order_to_plot=[1,0,2], max_percentile=99.0, spot_color='w', spot_mark_size=4,save_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find spots df_tracking.is_cluster is true in df_tracking\n",
    "df_tracking_is_cluster = df_tracking[df_tracking['is_cluster'] == True]\n",
    "df_tracking_is_cluster\n",
    "\n",
    "print('fraction of clusters detected: ' ,len(df_tracking_is_cluster)/len(df_tracking))\n",
    "\n",
    "#  df_tracking_is_cluster.cluster_size  > 10\n",
    "df_tracking_is_cluster_large = df_tracking_is_cluster[df_tracking_is_cluster['cluster_size'] >=2]\n",
    "df_tracking_is_cluster_large[['cluster_size','particle']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crops\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(AM)\n",
    "selection_threshold_for_channel_0 = 0.01\n",
    "selected_field = 'snr'  # options are: psf_sigma, snr, 'spot_int'\n",
    "plot_name = None\n",
    "plot_name_selected_field = results_folder.joinpath('spots_'+selected_field+'.png')\n",
    "log_scale = False\n",
    "array_selected_field_ch0= AM.Utilities().df_trajectories_to_array(dataframe=df_tracking, selected_field=selected_field+'_ch_0', fill_value='nans') \n",
    "array_selected_field_ch1= AM.Utilities().df_trajectories_to_array(dataframe=df_tracking, selected_field=selected_field+'_ch_1', fill_value='nans')\n",
    "AM.Plots().plot_crops_properties(list_particles_arrays=[array_selected_field_ch0, array_selected_field_ch1],figsize=(15, 3),save_plots=True,plot_name=plot_name_selected_field,selection_threshold=selection_threshold_for_channel_0, label =selected_field, log_scale=log_scale,list_colors=channel_names)\n",
    "mean_selected_field_ch0_all_particles = np.nanmedian(array_selected_field_ch0, axis=1)\n",
    "# plot snr histogram\n",
    "plot_name_snr = results_folder.joinpath('histogram_snr.png')\n",
    "mean_snr = AM.Plots().plot_histograms_from_df(df_tracking, selected_field=selected_field,figsize=(8,2), plot_name=plot_name_snr, bin_count=60, save_plot=True, list_colors= channel_names,remove_outliers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 9\n",
    "max_crops_to_display =120\n",
    "selected_time_point = None\n",
    "\n",
    "use_filtered_image= False\n",
    "if use_filtered_image:\n",
    "    croparray_filtered, mean_crop_filtered, first_appearance, crop_size = AM.CropArray(image=filtered_image, df_crops=df_tracking, crop_size=crop_size, remove_outliers=False, max_percentile=99.9,selected_time_point=selected_time_point).run()\n",
    "else:\n",
    "    croparray_filtered, mean_crop_filtered, first_appearance, crop_size = AM.CropArray(image=tested_image, df_crops=df_tracking, crop_size=crop_size, remove_outliers=False, max_percentile=99.9,selected_time_point=selected_time_point).run()\n",
    "\n",
    "# detect spots in mean_crop_filtered\n",
    "number_crops = first_appearance.shape[0]//crop_size\n",
    "flag_vector = np.zeros(number_crops, dtype=bool)\n",
    "for crop_id in range(number_crops):\n",
    "    flag_vector[crop_id]= AM.Utilities().is_spot_in_crop(crop_id, crop_size=crop_size, selected_color_channel=0, array_crops_YXC=mean_crop_filtered,show_plot=False)\n",
    "\n",
    "print('Number of detected spots SNR method:', np.sum(flag_vector))\n",
    "\n",
    "plot_name_crops_filter = results_folder.joinpath('crops.png')\n",
    "AM.Plots().plot_average_crops (mean_crop_filtered, crop_size, plot_orientation='horizontal',show_particle_labels=True,save_plots=True,plot_name=plot_name_crops_filter,max_crops_to_display=max_crops_to_display,flag_vector=flag_vector)\n",
    "\n",
    "AM.Plots().plot_average_crops (first_appearance, crop_size, plot_orientation='horizontal',show_particle_labels=True,save_plots=True,plot_name=plot_name_crops_filter,max_crops_to_display=max_crops_to_display,flag_vector=flag_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widget to select spots\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crop_widget(list_crops, crop_size, save_dir):\n",
    "    def display_crop(crop):\n",
    "        fig, ax = plt.subplots(figsize=(3, 3))\n",
    "        ax.matshow(crop, cmap='gray')\n",
    "        ax.grid(False)\n",
    "        plt.show()\n",
    "    number_crops = len(list_crops)\n",
    "    # Initialize counters for filenames\n",
    "    particle_counter = 0\n",
    "    no_particle_counter = 0\n",
    "    current_crop_id = 0  # Start from the first crop\n",
    "    # Create a folder if it doesn't exist, if it exists, remove it and create a new one\n",
    "    if os.path.exists(save_dir):\n",
    "        if save_dir == 'training_crops':\n",
    "            shutil.rmtree(save_dir)  # Remove the entire folder and its contents\n",
    "            os.makedirs(save_dir)\n",
    "    else:\n",
    "        os.makedirs(save_dir)\n",
    "    # Stack to store previously shown crops and filenames\n",
    "    crop_stack = []\n",
    "    filename_stack = []\n",
    "    crop_id_stack = []\n",
    "    # Create buttons\n",
    "    spot_present_button = widgets.Button(\n",
    "        description='Spot Present',\n",
    "        button_style='success',  # Green button\n",
    "        tooltip='Save crop as Spot Present'\n",
    "    )\n",
    "    no_spot_button = widgets.Button(\n",
    "        description='No Spot Present',\n",
    "        button_style='danger',  # Red button\n",
    "        tooltip='Save crop as No Spot Present'\n",
    "    )\n",
    "    back_button = widgets.Button(\n",
    "        description='Back',\n",
    "        button_style='warning',  # Yellow button\n",
    "        tooltip='Go back to the previous crop'\n",
    "    )\n",
    "    skip_button = widgets.Button(\n",
    "        description='Skip',\n",
    "        button_style='',  # Default button style\n",
    "        tooltip='Skip this crop'\n",
    "    )\n",
    "    button_box = widgets.HBox([spot_present_button, no_spot_button, skip_button, back_button])\n",
    "    output = widgets.Output()\n",
    "    filename_output = widgets.Output()\n",
    "    def update_crop():\n",
    "        nonlocal current_crop_id\n",
    "        if current_crop_id < number_crops:  # Ensure we don't go beyond the list\n",
    "            crop = list_crops[current_crop_id]\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                display_crop(crop)\n",
    "        else:\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                print(\"No more crops to display.\")\n",
    "    # Save crop when \"Spot Present\" button is clicked\n",
    "    def save_spot_present(b):\n",
    "        nonlocal particle_counter, current_crop_id\n",
    "        if current_crop_id < number_crops:\n",
    "            crop = list_crops[current_crop_id]\n",
    "            save_path = os.path.join(save_dir, f'particle_crop_{particle_counter}.png')\n",
    "            particle_counter += 1\n",
    "            im = Image.fromarray((crop * 255).astype(np.uint8))  # Normalize and convert to uint8\n",
    "            im.save(save_path)\n",
    "            # Save the current state to the stack\n",
    "            crop_stack.append(crop)\n",
    "            filename_stack.append(save_path)\n",
    "            crop_id_stack.append(current_crop_id)\n",
    "            # Display the saved filename\n",
    "            with filename_output:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Saved: {save_path}\")\n",
    "            # Move to the next crop after saving\n",
    "            current_crop_id += 1\n",
    "            update_crop()\n",
    "    # Save crop when \"No Spot Present\" button is clicked\n",
    "    def save_no_spot_present(b):\n",
    "        nonlocal no_particle_counter, current_crop_id\n",
    "        if current_crop_id < number_crops:\n",
    "            crop = list_crops[current_crop_id]\n",
    "\n",
    "            # Define the filename and save the crop\n",
    "            save_path = os.path.join(save_dir, f'no_particle_crop_{no_particle_counter}.png')\n",
    "            no_particle_counter += 1\n",
    "            im = Image.fromarray((crop*255 ).astype(np.uint8))  # Normalize and convert to uint8\n",
    "            im.save(save_path)\n",
    "            # Save the current state to the stack\n",
    "            crop_stack.append(crop)\n",
    "            filename_stack.append(save_path)\n",
    "            crop_id_stack.append(current_crop_id)\n",
    "\n",
    "            # Display the saved filename\n",
    "            with filename_output:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Saved: {save_path}\")\n",
    "            # Move to the next crop after saving\n",
    "            current_crop_id += 1\n",
    "            update_crop()\n",
    "    # Go back to the previous crop when \"Back\" button is clicked\n",
    "    def go_back(b):\n",
    "        nonlocal current_crop_id\n",
    "        if len(crop_stack) > 0 and len(filename_stack) > 0:\n",
    "            # Pop the last crop, filename, and crop_id\n",
    "            crop_stack.pop()\n",
    "            last_filename = filename_stack.pop()\n",
    "            last_crop_id = crop_id_stack.pop()\n",
    "            # Reload the last crop based on its crop ID and display it\n",
    "            current_crop_id = last_crop_id\n",
    "            crop = list_crops[current_crop_id]\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                display_crop(crop)\n",
    "            # Show the previous filename in the output\n",
    "            with filename_output:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Reverted to: {last_filename}\")\n",
    "        else:\n",
    "            with filename_output:\n",
    "                clear_output(wait=True)\n",
    "                print(\"No previous crop to go back to.\")\n",
    "    # Skip the crop when \"Skip\" button is clicked\n",
    "    def skip_crop(b):\n",
    "        nonlocal current_crop_id\n",
    "        if current_crop_id < number_crops:\n",
    "            current_crop_id += 1\n",
    "            update_crop()\n",
    "    # Attach button click events\n",
    "    spot_present_button.on_click(save_spot_present)\n",
    "    no_spot_button.on_click(save_no_spot_present)\n",
    "    back_button.on_click(go_back)\n",
    "    skip_button.on_click(skip_crop)\n",
    "    # Display widgets and the initial crop\n",
    "    display(button_box, output, filename_output)\n",
    "    update_crop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset = False\n",
    "if create_dataset:\n",
    "    selected_color_channel = 1\n",
    "    save_dir = 'training_crops'  # Define where to save the crops\n",
    "    #list_crops = AM.Utilities().normalize_crop_return_list(array_crops_YXC=mean_crop_filtered,crop_size=crop_size,selected_color_channel=0,normalize_to_255=False)\n",
    "    list_crops = AM.Utilities().standardize_spot_return_list(array_crops_YXC=mean_crop_filtered,crop_size=crop_size,selected_color_channel=0)\n",
    "    create_crop_widget(list_crops=list_crops, crop_size=crop_size, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_model_from_file = True\n",
    "model_name = 'particle_detection_cnn.pth'\n",
    "if load_model_from_file == False:\n",
    "    importlib.reload(ML)\n",
    "    model, training_losses, validation_losses = ML.run_network(image_dir='training_crops', num_epochs=10000,learning_rate = 0.0000005,batch_size = 256)\n",
    "    #model, training_losses, validation_losses  = ML.run_network(images_dir='training_crops', num_epochs=100, learning_rate=0.0000005, batch_size=256)\n",
    "    ML.save_model(model, path=model_name)\n",
    "else:\n",
    "    model = ML.ParticleDetectionCNN()\n",
    "    model_path = model_name\n",
    "    ML.load_model(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(training_losses, label='Training Loss', color='blue', marker='o', linestyle='-', linewidth=2, markersize=6)\n",
    "plt.plot(validation_losses, label='Validation Loss', color='red', marker='x', linestyle='--', linewidth=2, markersize=8)\n",
    "plt.title('Training and Validation Loss Over Epochs', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()  # Adjusts plot margins to give a better layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ML)\n",
    "selected_color_channel = 0\n",
    "list_crops = AM.Utilities().normalize_crop_return_list(array_crops_YXC=mean_crop_filtered,crop_size=crop_size,selected_color_channel=0,normalize_to_255=True)\n",
    "flag_vector = ML.predict_crops(model, list_crops,threshold=0.51)\n",
    "\n",
    "print(\"Number of predicted particles ML method:\", np.sum(flag_vector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AM.Plots().plot_average_crops (mean_crop_filtered, crop_size, plot_orientation='horizontal',show_particle_labels=True,save_plots=True,plot_name=plot_name_crops_filter,max_crops_to_display=120,flag_vector=flag_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Visualization\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network visualization saved as 'particle_detection_cnn_computation_graph.png'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# Create a function to visualize the model\n",
    "def visualize_model(model, input_size=(1, 1, 64, 64)):\n",
    "    # Create a dummy input tensor of the same shape as your actual inputs\n",
    "    dummy_input = torch.randn(*input_size)\n",
    "    # Perform a forward pass to capture the computation graph\n",
    "    output = model(dummy_input)\n",
    "    # Visualize the computation graph using torchviz\n",
    "    dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "    dot.render(\"particle_detection_cnn_computation_graph\", format=\"png\")  # Save as PNG\n",
    "    print(\"Network visualization saved as 'particle_detection_cnn_computation_graph.png'.\")\n",
    "\n",
    "# Visualize your model's computation graph\n",
    "model = ML.ParticleDetectionCNN()\n",
    "visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             320\n",
      "         MaxPool2d-2           [-1, 32, 32, 32]               0\n",
      "            Conv2d-3           [-1, 64, 32, 32]          18,496\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Linear-5                  [-1, 128]       2,097,280\n",
      "            Linear-6                    [-1, 1]             129\n",
      "================================================================\n",
      "Total params: 2,116,225\n",
      "Trainable params: 2,116,225\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 1.88\n",
      "Params size (MB): 8.07\n",
      "Estimated Total Size (MB): 9.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Assuming your ParticleDetectionCNN class is defined\n",
    "model = ML.ParticleDetectionCNN().to('cpu')  # You can use 'cuda' or 'mps' if available\n",
    "summary(model, input_size=(1, 64, 64))  # For a single-channel input of size 64x64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "# Initialize the model\n",
    "model =  ML.ParticleDetectionCNN().to('cpu') \n",
    "\n",
    "# Create a dummy input tensor with the same size as your model input (e.g., a 64x64 grayscale image)\n",
    "dummy_input = torch.randn(1, 1, 64, 64)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(model, dummy_input, \"particle_detection_model.onnx\",\n",
    "                  input_names=['input'], output_names=['output'],\n",
    "                  verbose=True)\n",
    "\n",
    "print(\"Model exported to particle_detection_model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Advanced_Microscopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
