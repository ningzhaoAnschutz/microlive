{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Code - Training with real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import socket\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import io\n",
    "from IPython.display import display, Image as IPImage, clear_output\n",
    "import importlib\n",
    "import warnings\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Suppress warnings if needed\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def find_src_directory(current_directory: Path) -> Path:\n",
    "    # Loop through the parent directories\n",
    "    for parent in current_directory.parents:\n",
    "        potential_src = parent / 'src'\n",
    "        if potential_src.is_dir():\n",
    "            return potential_src\n",
    "    return None\n",
    "current_dir = pathlib.Path().absolute()\n",
    "Advanced_Microscopy_dir = find_src_directory(current_dir)\n",
    "sys.path.append(str(Advanced_Microscopy_dir))\n",
    "\n",
    "# Local module imports\n",
    "import Advanced_Microscopy as AM \n",
    "import ML_SpotDetection as ML\n",
    "\n",
    "# Reload modules if they are under active development\n",
    "importlib.reload(AM)\n",
    "importlib.reload(ML)\n",
    "\n",
    "# Load pre-trained model\n",
    "model = ML.ParticleDetectionCNN()\n",
    "model_path = 'particle_detection_cnn.pth'\n",
    "ML.load_model(model, model_path)\n",
    "\n",
    "# Utility functions\n",
    "def find_src_directory(current_directory: Path) -> Path:\n",
    "    \"\"\" Finds the 'src' directory by navigating up from the current directory. \"\"\"\n",
    "    for parent in current_directory.parents:\n",
    "        potential_src = parent / 'src'\n",
    "        if potential_src.is_dir():\n",
    "            return potential_src\n",
    "    return None\n",
    "\n",
    "# Display computer info\n",
    "computer_name = socket.gethostname()\n",
    "computer_user_name = computer_name.split('.')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_my_folder = pathlib.Path(r\"/Users/nzlab-la/Library/CloudStorage/OneDrive-TheUniversityofColoradoDenver/General - Zhao (NZ) Lab/Microscope/Luis Aguilera/Live cell imaging_Folding & Nascent chains\")\n",
    "data_folder_path =path_my_folder.joinpath(r\"20240806 pNZ212 and pRS001_JF646_NoDelay_ch0 folding_ch1 nascent chains.lif\")\n",
    "list_images, list_names, pixel_xy_um, voxel_z_um, channel_names, number_color_channels,list_time_intervals, bit_depth = AM.ReadLif(data_folder_path,show_metadata=False,save_tif=False,save_png=True,format='TZYXC').read()\n",
    "selected_image = 4\n",
    "real_image =list_images[selected_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_time_points = real_image.shape[0]\n",
    "filtered_image_normalized = np.zeros_like(real_image)\n",
    "for i in range(number_time_points):\n",
    "    filtered_image_normalized[i] = AM.RemoveExtrema(real_image[i],min_percentile=0.5, max_percentile=99).remove_outliers() \n",
    "\n",
    "# renaming filtered_image_normalized as real_image\n",
    "real_image = filtered_image_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = batch_size*200\n",
    "learning_rate = 0.000001\n",
    "grid_size = 11\n",
    "crop_size = grid_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = Path('results_'+data_folder_path.stem + '_cell_id_'+str(selected_image))\n",
    "df_tracking = pd.read_csv(results_folder.joinpath('results_df_tracking.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crops_from_image(real_image,df_tracking=None, minimal_snr = 0.8, grid_size = 11, selected_color_channel = 0):\n",
    "    \n",
    "    if df_tracking is not None:\n",
    "        df_tracking_selected = df_tracking[df_tracking['snr_ch_0'] >minimal_snr]\n",
    "        time = np.random.randint(real_image.shape[0])\n",
    "        frame_data = df_tracking_selected[df_tracking_selected['frame'] == time]\n",
    "        number_spots = len(frame_data)\n",
    "        selected_spot = np.random.randint(number_spots)\n",
    "        positions = frame_data[['z', 'y', 'x']].to_numpy().astype(int)\n",
    "        z = positions[selected_spot,0]\n",
    "        y = positions[selected_spot,1]\n",
    "        x = positions[selected_spot,2]\n",
    "    else:\n",
    "        time = np.random.randint(real_image.shape[0])\n",
    "        x = np.random.randint(grid_size, real_image.shape[3] - grid_size)\n",
    "        y = np.random.randint(grid_size, real_image.shape[2] - grid_size)\n",
    "        z = np.random.randint(real_image.shape[1])\n",
    "    crop = real_image[time, z, \n",
    "                    y-grid_size//2: y+grid_size//2 + 1,\n",
    "                    x-grid_size//2: x+grid_size//2 + 1, selected_color_channel]\n",
    "    if np.max(crop) > 0:\n",
    "        crop= ((crop - np.min(crop)) / (np.max(crop) - np.min(crop))) * 255\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset folder\n",
    "traning_dataset_folder_real_data = 'training_crops_real_data'\n",
    "if os.path.exists(traning_dataset_folder_real_data):\n",
    "    shutil.rmtree(traning_dataset_folder_real_data)\n",
    "Path(traning_dataset_folder_real_data).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataset with 100 simulated single spots\n",
    "number_simulated_single_spots = 1000\n",
    "for i in range(number_simulated_single_spots):\n",
    "    z = create_crops_from_image(real_image,df_tracking)\n",
    "    im = Image.fromarray((z).astype(np.uint8))  # Normalize and convert to uint8\n",
    "    im.save(f'{traning_dataset_folder_real_data}/particle_{i}.png')\n",
    "\n",
    "\n",
    "# creating a dataset without spots start counter from 0 \n",
    "number_simulated_no_spots = 1000\n",
    "for i in range(number_simulated_no_spots):\n",
    "    z = create_crops_from_image(real_image,df_tracking=None)\n",
    "    im = Image.fromarray((z).astype(np.uint8))  # Normalize and convert to uint8\n",
    "    im.save(f'{traning_dataset_folder_real_data}/no_particle_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_from_file = False\n",
    "model_name_real_data = 'particle_detection_cnn_real_data.pth'\n",
    "if load_model_from_file == False:\n",
    "    importlib.reload(ML)\n",
    "    model_real_data, training_losses_real_data, validation_losses_real_data = ML.run_network(image_dir=traning_dataset_folder_real_data, num_epochs=num_epochs,learning_rate = learning_rate,batch_size = batch_size)\n",
    "    ML.save_model(model_real_data, path=model_name_real_data)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(training_losses_real_data, label='Training Loss', color='blue', marker='o', linestyle='-', linewidth=2, markersize=6)\n",
    "    plt.plot(validation_losses_real_data, label='Validation Loss', color='red', marker='x', linestyle='--', linewidth=2, markersize=8)\n",
    "    plt.title('Training and Validation Loss Over Epochs', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()  # Adjusts plot margins to give a better layout\n",
    "    plt.show()\n",
    "else:\n",
    "    model_real_data = ML.ParticleDetectionCNN()\n",
    "    model_path_real_data = model_name_real_data\n",
    "    ML.load_model(model_real_data, model_path_real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training_losses_real_data, validation_losses_real_data as numpy arrays\n",
    "np.save('training_losses_real_data.npy', training_losses_real_data)\n",
    "np.save('validation_losses_real_data.npy', validation_losses_real_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model with simulated data\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spot(amplitude=None, sigma=None, grid_size=11, mu_x=None, mu_y=None, percentage_noise=None, create_spot=False, number_spots=1,real_image= None,selected_color_channel=0):\n",
    "    x = np.linspace(0, grid_size - 1, grid_size)\n",
    "    y = np.linspace(0, grid_size - 1, grid_size)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    if real_image is not None:\n",
    "        selected_z = np.random.randint(0, real_image.shape[1])\n",
    "        selected_time = np.random.randint(0, real_image.shape[0])\n",
    "        position_x = np.random.randint(grid_size, real_image.shape[3]- grid_size)\n",
    "        position_y = np.random.randint(grid_size, real_image.shape[2]- grid_size)\n",
    "        max_val_real_image = np.percentile(real_image[selected_time, selected_z, :, :, selected_color_channel], 100)\n",
    "        z = real_image[selected_time, selected_z, position_y:position_y+grid_size, position_x:position_x+grid_size, selected_color_channel]\n",
    "        basal_intensity = np.random.randint(100, 255//2)\n",
    "        # min max normalization\n",
    "        z = (z / max_val_real_image)*basal_intensity\n",
    "        if amplitude is None:\n",
    "            # random int between 10 and 100\n",
    "            amplitude = np.random.rand()*np.random.randint(2,4) *basal_intensity\n",
    "        else:\n",
    "            amplitude = amplitude\n",
    "    else:\n",
    "        z = np.zeros((grid_size, grid_size))\n",
    "    \n",
    "    if create_spot == False:\n",
    "        sigma = 6\n",
    "        percentage_noise = 0.01 + np.random.rand() * 0.05\n",
    "        mu_x, mu_y = (grid_size/2)-0.5, (grid_size/2)-0.5  # Default to center if not specified\n",
    "        if real_image is None:\n",
    "            spot_intensity = amplitude * np.exp(-((x - mu_x)**2 + (y - mu_y)**2) / (2 * sigma**2))\n",
    "            z += spot_intensity\n",
    "            if percentage_noise > 0:\n",
    "                z = z + np.random.normal(0, amplitude*percentage_noise, z.shape)  \n",
    "        # shuffle all the values in the image to ensure there is no spot \n",
    "        z = z.flatten()\n",
    "        np.random.shuffle(z)\n",
    "        z = z.reshape(grid_size, grid_size)\n",
    "    else:\n",
    "        for _ in range(number_spots):\n",
    "            if percentage_noise is None:\n",
    "                percentage_noise_temp = 0.01 + np.random.rand() * 0.05\n",
    "            else:\n",
    "                percentage_noise_temp = percentage_noise\n",
    "            if amplitude is None:\n",
    "                # random number between 200 and 255\n",
    "                amplitude_temp = int( 200 + np.random.rand() * 55) \n",
    "            else:\n",
    "                amplitude_temp = amplitude\n",
    "            if sigma is None:\n",
    "                # random number between 1 and 2.5\n",
    "                sigma_temp = 0.5 + np.random.rand() * 1.5\n",
    "            else:\n",
    "                sigma_temp = sigma\n",
    "            if mu_x is None or mu_y is None:\n",
    "                # Generate random coordinates within the range 2 to 6\n",
    "                # generate the random coordinates within the range of -3 to 3 from the center\n",
    "                image_center = grid_size//2\n",
    "                number_of_pixels_around = np.min([image_center-1, 4])\n",
    "                mu_x_temp = image_center + np.random.randint(-number_of_pixels_around, number_of_pixels_around)\n",
    "                mu_y_temp = image_center + np.random.randint(-number_of_pixels_around, number_of_pixels_around)\n",
    "                #mu_x_temp = 3 + np.random.rand() * 3\n",
    "\n",
    "                #mu_x_temp = 3 + np.random.rand() * 3\n",
    "                #mu_y_temp = 3 + np.random.rand() * 3\n",
    "                #mu_x_temp = 3 + np.random.rand() * 3\n",
    "                #mu_y_temp = 3 + np.random.rand() * 3\n",
    "            # Compute Gaussian intensity\n",
    "            spot_intensity = amplitude_temp * np.exp(-((x - mu_x_temp)**2 + (y - mu_y_temp)**2) / (2 * sigma_temp**2))\n",
    "            z += spot_intensity  # Add intensity to the spot image\n",
    "        # adding noise to the image if not real image\n",
    "        if real_image is None:\n",
    "            amplitude = amplitude_temp\n",
    "            percentage_noise = percentage_noise_temp\n",
    "            if percentage_noise > 0:\n",
    "                percentage_noise_temp = 0.01 + np.random.rand() * 0.1\n",
    "                z = z + np.random.normal(0, amplitude * percentage_noise, z.shape)\n",
    "    # Normalize and add noise if applicable\n",
    "    if z.max() > 0:\n",
    "        z = ((z - np.min(z)) / (np.max(z) - np.min(z))) * 255\n",
    "    z = np.clip(z, 0, 255).astype(np.uint8)  # Ensure values are within uint8 range\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset folder\n",
    "traning_dataset_folder_simulated_data = 'training_crops_simulated_data'\n",
    "# remove the folder if it exists\n",
    "if os.path.exists(traning_dataset_folder_simulated_data):\n",
    "    shutil.rmtree(traning_dataset_folder_simulated_data)\n",
    "Path(traning_dataset_folder_simulated_data).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_x = None  # Center x-coordinate 2-6\n",
    "mu_y = None  # Center y-coordinate 2-6\n",
    "amplitude = None\n",
    "sigma = None\n",
    "number_doubles = 256\n",
    "# creating the dataset with 100 simulated single spots\n",
    "number_simulated_single_spots = 500- number_doubles #2000\n",
    "for i in range(number_simulated_single_spots):\n",
    "    z = plot_spot(amplitude, sigma, grid_size, mu_x, mu_y, percentage_noise=None,create_spot=True,number_spots=1,real_image=real_image)\n",
    "    im = Image.fromarray((z).astype(np.uint8))  # Normalize and convert to uint8\n",
    "    im.save(f'{traning_dataset_folder_simulated_data}/particle_{i}.png')\n",
    "\n",
    "# creating the dataset with 100 simulated double spots continue from the last index\n",
    "number_simulated_double_spots = number_doubles\n",
    "for i in range(number_simulated_double_spots):\n",
    "    z = plot_spot(amplitude, sigma, grid_size, mu_x, mu_y, percentage_noise=None,create_spot=True,number_spots=2,real_image=real_image)\n",
    "    im = Image.fromarray((z).astype(np.uint8))  # Normalize and convert to uint8\n",
    "    im.save(f'{traning_dataset_folder_simulated_data}/particle_{i+number_simulated_single_spots}.png')\n",
    "\n",
    "# adding the real data \n",
    "number_real_spots = 1000\n",
    "for i in range(number_real_spots):\n",
    "    z = create_crops_from_image(real_image,df_tracking)\n",
    "    im = Image.fromarray((z).astype(np.uint8))  # Normalize and convert to uint8\n",
    "    im.save(f'{traning_dataset_folder_simulated_data}/particle_{i+number_simulated_double_spots+number_simulated_single_spots}.png')\n",
    "\n",
    "# creating a dataset without spots start counter from 0 \n",
    "number_simulated_no_spots = 500 #2000\n",
    "for i in range(number_simulated_no_spots):\n",
    "    z = plot_spot(amplitude, sigma, grid_size, mu_x, mu_y, percentage_noise=None,create_spot=False,number_spots=0,real_image=real_image)\n",
    "    im = Image.fromarray((z).astype(np.uint8))  # Normalize and convert to uint8\n",
    "    im.save(f'{traning_dataset_folder_simulated_data}/no_particle_{i}.png')\n",
    "\n",
    "# creating a dataset without spots start counter from 0 \n",
    "number_real_no_spots = 500\n",
    "for i in range(number_real_no_spots):\n",
    "    z = create_crops_from_image(real_image,df_tracking=None)\n",
    "    im = Image.fromarray((z).astype(np.uint8))  # Normalize and convert to uint8\n",
    "    im.save(f'{traning_dataset_folder_simulated_data}/no_particle_{number_simulated_no_spots+i}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model machine learning tranining with simulated data\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_from_file = False\n",
    "model_name_simulated_data = 'particle_detection_cnn_simulated_data.pth'\n",
    "if load_model_from_file == False:\n",
    "    importlib.reload(ML)\n",
    "    model_simulated_data, training_losses_simulated_data, validation_losses_simulated_data = ML.run_network(image_dir=traning_dataset_folder_simulated_data, num_epochs=num_epochs,learning_rate = learning_rate,batch_size = batch_size)\n",
    "    ML.save_model(model_simulated_data, path=model_name_simulated_data)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(training_losses_simulated_data, label='Training Loss', color='blue', marker='o', linestyle='-', linewidth=2, markersize=6)\n",
    "    plt.plot(validation_losses_simulated_data, label='Validation Loss', color='red', marker='x', linestyle='--', linewidth=2, markersize=8)\n",
    "    plt.title('Training and Validation Loss Over Epochs', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()  # Adjusts plot margins to give a better layout\n",
    "    plt.show()\n",
    "else:\n",
    "    model_simulated_data = ML.ParticleDetectionCNN()\n",
    "    ML.load_model(model_simulated_data, model_name_simulated_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses_simulated_data, label='Training Loss', color='blue',  linestyle='-', linewidth=2, markersize=6)\n",
    "plt.plot(validation_losses_simulated_data, label='Validation Loss', color='red', linestyle='--', linewidth=2, markersize=8)\n",
    "plt.title('Training and Validation Loss Over Epochs', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()  # Adjusts plot margins to give a better layout\n",
    "# make y axis log scale\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training_losses_simulated_data, validation_losses_simulated_data as numpy arrays\n",
    "np.save('training_losses_simulated_data.npy', training_losses_simulated_data)\n",
    "np.save('validation_losses_simulated_data.npy', validation_losses_simulated_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with user reinforced data.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading a list of crops \n",
    "max_crops_to_display =50\n",
    "selected_time_point = None\n",
    "croparray_filtered, mean_crop_filtered, first_appearance, crop_size = AM.CropArray(image=filtered_image_normalized, df_crops=df_tracking, crop_size=crop_size, remove_outliers=False, max_percentile=99.9,selected_time_point=selected_time_point).run()\n",
    "list_crops = AM.Utilities().normalize_crop_return_list(array_crops_YXC=mean_crop_filtered,crop_size=crop_size,selected_color_channel=0,normalize_to_255=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impot the human selection\n",
    "a = np.load('human_selection_Jake.npy')\n",
    "b = np.load('human_selection_Luis.npy')\n",
    "c = np.load('human_selection_Rhiannon.npy')\n",
    "#d = np.load('human_selection_Nate.npy')\n",
    "\n",
    "flag_vector_ground_truth_all_true = np.logical_and.reduce([a, b, c])\n",
    "flag_vector_ground_truth_all_false = np.logical_not(np.logical_or.reduce([a, b, c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_dataset_folder_human_selection = 'training_crops_human_selection'\n",
    "if os.path.exists(traning_dataset_folder_human_selection):\n",
    "    shutil.rmtree(traning_dataset_folder_human_selection)\n",
    "Path(traning_dataset_folder_human_selection).mkdir(parents=True, exist_ok=True)\n",
    "for i in range(len(list_crops)):\n",
    "    if flag_vector_ground_truth_all_true[i] == True:\n",
    "        z = list_crops[i]\n",
    "        im = Image.fromarray((z).astype(np.uint8))  # Normalize and convert to uint8\n",
    "        im.save(f'{traning_dataset_folder_human_selection}/particle_{i}.png')\n",
    "for i in range(len(list_crops)):\n",
    "    if flag_vector_ground_truth_all_false[i] == True:\n",
    "        z = list_crops[i]\n",
    "        im = Image.fromarray((z).astype(np.uint8))  # Normalize and convert to uint8\n",
    "        im.save(f'{traning_dataset_folder_human_selection}/no_particle_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_from_file = False\n",
    "model_human_selected_data_path = 'particle_detection_cnn_human_selected_data.pth'\n",
    "if load_model_from_file == False:\n",
    "    importlib.reload(ML)\n",
    "    model_human_selected_data, training_losses_human_selected_data, validation_losses_human_selected_data = ML.run_network(image_dir=traning_dataset_folder_human_selection, num_epochs=num_epochs,learning_rate = learning_rate,batch_size = batch_size)\n",
    "    ML.save_model(model_human_selected_data, path=model_human_selected_data_path)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(training_losses_human_selected_data, label='Training Loss', color='blue', marker='o', linestyle='-', linewidth=2, markersize=6)\n",
    "    plt.plot(validation_losses_human_selected_data, label='Validation Loss', color='red', marker='x', linestyle='--', linewidth=2, markersize=8)\n",
    "    plt.title('Training and Validation Loss Over Epochs', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()  # Adjusts plot margins to give a better layout\n",
    "    plt.show()\n",
    "else:\n",
    "    model_human_selected_data = ML.ParticleDetectionCNN()\n",
    "    ML.load_model(model_human_selected_data, model_human_selected_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the model with testing data \n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading a list of crops \n",
    "\n",
    "# max_crops_to_display =50\n",
    "# selected_time_point = None\n",
    "# croparray_filtered, mean_crop_filtered, first_appearance, crop_size = AM.CropArray(image=filtered_image_normalized, df_crops=df_tracking, crop_size=crop_size, remove_outliers=False, max_percentile=99.9,selected_time_point=selected_time_point).run()\n",
    "# list_crops = AM.Utilities().normalize_crop_return_list(array_crops_YXC=mean_crop_filtered,crop_size=crop_size,selected_color_channel=0,normalize_to_255=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SNR method\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_crops = first_appearance.shape[0]//crop_size\n",
    "flag_vector_SNR = np.zeros(number_crops, dtype=bool)\n",
    "for crop_id in range(number_crops):\n",
    "    flag_vector_SNR[crop_id]= AM.Utilities().is_spot_in_crop(crop_id, crop_size=crop_size, selected_color_channel=0, array_crops_YXC=mean_crop_filtered,show_plot=False,snr_threshold=1.1)\n",
    "print('Number of detected spots SNR method:', np.sum(flag_vector_SNR))\n",
    "AM.Plots().plot_average_crops (mean_crop_filtered, crop_size, plot_orientation='horizontal',show_particle_labels=True,save_plots=False,plot_name=None,max_crops_to_display=max_crops_to_display,flag_vector=flag_vector_SNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ML method with Real data\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ML)\n",
    "selected_color_channel = 0\n",
    "flag_vector_ML_real = ML.predict_crops(model_real_data, list_crops,threshold=0.67)\n",
    "print(\"Number of predicted particles ML method:\", np.sum(flag_vector_ML_real))\n",
    "AM.Plots().plot_average_crops (mean_crop_filtered, crop_size, plot_orientation='horizontal',show_particle_labels=True,save_plots=False,plot_name=None,max_crops_to_display=max_crops_to_display,flag_vector=flag_vector_ML_real)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ML method with simulated data\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ML)\n",
    "selected_color_channel = 0\n",
    "flag_vector_ML_simulated = ML.predict_crops(model_simulated_data, list_crops,threshold=0.67)\n",
    "print(\"Number of predicted particles ML method:\", np.sum(flag_vector_ML_simulated))\n",
    "AM.Plots().plot_average_crops (mean_crop_filtered, crop_size, plot_orientation='horizontal',show_particle_labels=True,save_plots=False,plot_name=None,max_crops_to_display=max_crops_to_display,flag_vector=flag_vector_ML_simulated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ML method with human selected data\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ML)\n",
    "selected_color_channel = 0\n",
    "flag_vector_ML_human_selected_data = ML.predict_crops(model_human_selected_data, list_crops,threshold=0.6)\n",
    "print(\"Number of predicted particles ML method human selected data:\", np.sum(flag_vector_ML_human_selected_data))\n",
    "AM.Plots().plot_average_crops (mean_crop_filtered, crop_size, plot_orientation='horizontal',show_particle_labels=True,save_plots=False,plot_name=None,max_crops_to_display=max_crops_to_display,flag_vector=flag_vector_ML_human_selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impot the human selection\n",
    "a = np.load('human_selection_1.npy')\n",
    "b = np.load('human_selection_2.npy')\n",
    "c = np.load('human_selection_3.npy')\n",
    "d = np.load('human_selection_4.npy')\n",
    "\n",
    "# all true\n",
    "flag_vector_ground_truth_all_true = np.logical_and.reduce([a, b, c,d])\n",
    "# all false\n",
    "flag_vector_ground_truth_all_false = np.logical_not(np.logical_or.reduce([a, b, c,d]))\n",
    "# flag at least two true\n",
    "flag_vector_ground_truth_at_least_two_true = (a.astype(int) + b.astype(int) + c.astype(int) + d.astype(int)) >= 2\n",
    "\n",
    "# List of boolean arrays\n",
    "human_selection_arrays = [a, b, c, d]\n",
    "flag_vector_consensus = np.sum(human_selection_arrays, axis=0) >= (len(human_selection_arrays) / 2)\n",
    "\n",
    "# number of flag_vector_ground_truth_all_false\n",
    "number_of_true = np.sum(flag_vector_consensus)\n",
    "# sume the inverse of the human selection arrays\n",
    "number_of_false = np.sum(np.logical_not(flag_vector_consensus), axis=0)\n",
    "#number_of_true = np.sum(human_selection_arrays)\n",
    "print('Number of true:', number_of_true)\n",
    "print('Number of false:', number_of_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ML)\n",
    "selected_color_channel = 0\n",
    "print(\"Number of predicted particles ML method:\", np.sum(flag_vector_consensus))\n",
    "AM.Plots().plot_average_crops (mean_crop_filtered, crop_size, plot_orientation='horizontal',show_particle_labels=True,save_plots=False,plot_name=None,max_crops_to_display=120,flag_vector=flag_vector_consensus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(predicted, ground_truth):\n",
    "    TP = np.sum((predicted == True) & (ground_truth == True))\n",
    "    FP = np.sum((predicted == True) & (ground_truth == False))\n",
    "    TN = np.sum((predicted == False) & (ground_truth == False))\n",
    "    FN = np.sum((predicted == False) & (ground_truth == True))\n",
    "    # Calculate accuracy\n",
    "    accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "    return TP, FP, TN, FN, accuracy\n",
    "\n",
    "# Calculate for SNR method\n",
    "TP_SNR, FP_SNR, TN_SNR, FN_SNR, accuracy_SNR = calculate_performance(flag_vector_SNR, flag_vector_consensus)\n",
    "print(f\"SNR Method - Accuracy: {accuracy_SNR:.2%} (TP: {TP_SNR}, FP: {FP_SNR}, TN: {TN_SNR}, FN: {FN_SNR})\")\n",
    "\n",
    "# Calculate for ML method\n",
    "TP_ML, FP_ML, TN_ML, FN_ML, accuracy_ML = calculate_performance(flag_vector_ML_real, flag_vector_consensus)\n",
    "print(f\"ML Method - Real Data - Accuracy: {accuracy_ML:.2%} (TP: {TP_ML}, FP: {FP_ML}, TN: {TN_ML}, FN: {FN_ML})\")\n",
    "\n",
    "# Calculate for ML method\n",
    "TP_ML, FP_ML, TN_ML, FN_ML, accuracy_ML = calculate_performance(flag_vector_ML_simulated, flag_vector_consensus)\n",
    "print(f\"ML Method- Simulated Data - Accuracy: {accuracy_ML:.2%} (TP: {TP_ML}, FP: {FP_ML}, TN: {TN_ML}, FN: {FN_ML})\")\n",
    "\n",
    "# Calculate for ML method human selected data\n",
    "TP_ML, FP_ML, TN_ML, FN_ML, accuracy_ML = calculate_performance(flag_vector_ML_human_selected_data, flag_vector_consensus)\n",
    "print(f\"ML Method- Human Selected Data - Accuracy: {accuracy_ML:.2%} (TP: {TP_ML}, FP: {FP_ML}, TN: {TN_ML}, FN: {FN_ML})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficient between the arrays\n",
    "corr_ab = np.corrcoef(a, b)[0, 1]\n",
    "corr_ac = np.corrcoef(a, c)[0, 1]\n",
    "corr_bc = np.corrcoef(b, c)[0, 1]\n",
    "corr_ad = np.corrcoef(a, d)[0, 1]\n",
    "\n",
    "print(f\"Correlation between 1 and 2: {corr_ab}\")\n",
    "print(f\"Correlation between 1 and 3: {corr_ac}\")\n",
    "print(f\"Correlation between 2 and 3: {corr_bc}\")\n",
    "print(f\"Correlation between 2 and 4: {corr_ad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "global_results = []\n",
    "def create_crop_widget(list_crops):\n",
    "    number_crops = len(list_crops)\n",
    "    current_crop_id = 0\n",
    "    RESHAPE_IMAGE_SIZE = 32\n",
    "    button_box = widgets.HBox()  # This will hold our buttons\n",
    "    output = widgets.Output()\n",
    "    info_label = widgets.Label()  # Label to display crop info\n",
    "    \n",
    "    def update_info_label():\n",
    "        info_label.value = f\"Spot {current_crop_id + 1}/{number_crops}\"\n",
    "    \n",
    "    def display_crop(crop_id):\n",
    "        crop = list_crops[crop_id]\n",
    "        # transform crop \n",
    "\n",
    "\n",
    "        crop = np.array(Image.fromarray(crop).resize((RESHAPE_IMAGE_SIZE, RESHAPE_IMAGE_SIZE)))\n",
    "        # min max normalization\n",
    "        crop = (crop - np.min(crop)) / (np.max(crop) - np.min(crop))\n",
    "        # remove the 0.1 and 99.9 percentile\n",
    "        crop = crop - np.percentile(crop, 0.01)\n",
    "        crop = crop / np.percentile(crop, 99.95)\n",
    "        #crop = AM.RemoveExtrema(crop, min_percentile=0.5, max_percentile=99.5).remove_outliers() \n",
    "        # normalize to 255\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            update_info_label()\n",
    "            plt.imshow(crop, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    def on_button_clicked(is_spot):\n",
    "        # Append or replace the result in the global list\n",
    "        if len(global_results) > current_crop_id:\n",
    "            global_results[current_crop_id] = is_spot\n",
    "        else:\n",
    "            global_results.append(is_spot)\n",
    "        move_next()\n",
    "\n",
    "    def move_next():\n",
    "        nonlocal current_crop_id\n",
    "        current_crop_id += 1\n",
    "        if current_crop_id < number_crops:\n",
    "            display_crop(current_crop_id)\n",
    "        else:\n",
    "            # Show final message when done\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                print(\"No more crops to display.\")\n",
    "                print(\"Results:\", global_results)\n",
    "\n",
    "    def move_back():\n",
    "        nonlocal current_crop_id\n",
    "        if current_crop_id > 0:\n",
    "            current_crop_id -= 1\n",
    "            display_crop(current_crop_id)\n",
    "\n",
    "    # Creating buttons for user interaction\n",
    "    spot_present_button = widgets.Button(description='Spot Present', button_style='success')\n",
    "    no_spot_button = widgets.Button(description='No Spot Present', button_style='danger')\n",
    "    back_button = widgets.Button(description='Back', button_style='info')\n",
    "\n",
    "    spot_present_button.on_click(lambda b: on_button_clicked(True))\n",
    "    no_spot_button.on_click(lambda b: on_button_clicked(False))\n",
    "    back_button.on_click(lambda b: move_back())\n",
    "\n",
    "    button_box.children = [back_button, spot_present_button, no_spot_button, info_label]\n",
    "\n",
    "    # Initial display setup\n",
    "    display(button_box, output)\n",
    "    display_crop(current_crop_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_crop_widget(list_crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_selection = np.array(global_results)\n",
    "human_selection = np.pad(human_selection, (0, len(list_crops) - len(human_selection)), 'constant', constant_values=(0, 0))\n",
    "# save the human selection\n",
    "#np.save('human_selection_Nate.npy', human_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Advanced_Microscopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
